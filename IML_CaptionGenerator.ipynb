{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IML_CaptionGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Tensorflow and Keras\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0aQoujRU4m7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import keras"
      ],
      "metadata": {
        "id": "etYI1V4W4rDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extaction\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_jxJhblT4xRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "def extract_features(dir):\n",
        "\tmodel = VGG16()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\tfeatures = dict()\n",
        "\tfor name in listdir(dir):\n",
        "\t\tfilename = dir + '/' + name\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\tfeature = model.predict(image, verbose=0)\n",
        "\t\timage_id = name.split('.')[0]\n",
        "\t\tfeatures[image_id] = feature\n",
        "\t\tprint('>%s' % name)\n",
        "\treturn features\n",
        "dir = 'data/dataset/Flickr8k_Dataset'\n",
        "features = extract_features(dir)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "dump(features, open('tools/extracted_features.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "RMmQwsCJ40kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Vocabulary\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "y6gT5l7u5B1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
        "\n",
        "def to_vocabulary(descriptions):\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "\n",
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        "\n",
        "filename = 'data/dataset/Flickr8k_text/Flickr8k.token.txt'\n",
        "doc = load_doc(filename)\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "clean_descriptions(descriptions)\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))\n",
        "save_descriptions(descriptions, 'tools/descriptions.txt')"
      ],
      "metadata": {
        "id": "NhL3qJeI5SAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Definition and Fitting\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "97QqJltR5usW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "def load_photo_features(filename, dataset):\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)\n",
        "\n",
        "def create_sequences(tokenizer, max_length, desc_list, photo, vocab_size):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\tfor desc in desc_list:\n",
        "\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\tfor i in range(1, len(seq)):\n",
        "\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\tX1.append(photo)\n",
        "\t\t\tX2.append(in_seq)\n",
        "\t\t\ty.append(out_seq)\n",
        "\treturn array(X1), array(X2), array(y)\n",
        "\n",
        "def define_model(vocab_size, max_length):\n",
        "\tinputs1 = Input(shape=(4096,))\n",
        "\tfe1 = Dropout(0.5)(inputs1)\n",
        "\tfe2 = Dense(256, activation='relu')(fe1)\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "\tse2 = Dropout(0.5)(se1)\n",
        "\tse3 = LSTM(256)(se2)\n",
        "\tdecoder1 = add([fe2, se3])\n",
        "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\tmodel.summary()\n",
        "\treturn model\n",
        "\n",
        "def data_generator(descriptions, photos, tokenizer, max_length, vocab_size):\n",
        "\twhile 1:\n",
        "\t\tfor key, desc_list in descriptions.items():\n",
        "\t\t\tphoto = photos[key][0]\n",
        "\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo, vocab_size)\n",
        "\t\t\tyield [in_img, in_seq], out_word\n",
        "\n",
        "filename = 'data/datasets/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "train_descriptions = load_clean_descriptions('tools/descriptions.txt', train)\n",
        "train_features = load_photo_features('tools/features.pkl', train)\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = max_length(train_descriptions)\n",
        "\n",
        "model = define_model(vocab_size, max_length)\n",
        "epochs = 12\n",
        "steps = len(train_descriptions)\n",
        "for i in range(epochs):\n",
        "\tgenerator = data_generator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\n",
        "\tmodel.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "\tmodel.save('model/model_' + str(i) + '.h5')"
      ],
      "metadata": {
        "id": "S-mOH3Ge5uED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2VEq2AaJ6EhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "def load_photo_features(filename, dataset):\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)\n",
        "\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\tin_text = 'startseq'\n",
        "\tfor i in range(max_length):\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\tin_text += ' ' + word\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n",
        "\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\treferences = [d.split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t#BLEU score for evaluation\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "#Training dataset\n",
        "filename = 'data/datasets/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "train_descriptions = load_clean_descriptions('tools/descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "max_length = max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)\n",
        "\n",
        "filename = 'data/datasets/Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "test_descriptions = load_clean_descriptions('tools/descriptions.txt', test)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "test_features = load_photo_features('tools/extracted_features.pkl', test)\n",
        "print('Photos: test=%d' % len(test_features))\n",
        "\n",
        "filename = 'model/model_11.h5'\n",
        "model = load_model(filename)\n",
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "LT1LfChg6HbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Tokenizer\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S17y9vVD8m5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from pickle import dump\n",
        "\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "filename = 'data/datasets/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "train_descriptions = load_clean_descriptions('tools/descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "# Creating the tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "# Saving the tokenizer\n",
        "dump(tokenizer, open('tools/tokenizer.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "qsOVa9UW83GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caption Generation\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eDB2Xa7q9YJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "\n",
        "def extract_features(filename):\n",
        "\tmodel = VGG16()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\timage = load_img(filename, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\timage = preprocess_input(image)\n",
        "\tfeature = model.predict(image, verbose=0)\n",
        "\treturn feature\n",
        "\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\tin_text = 'startseq'\n",
        "\tfor i in range(max_length):\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\tin_text += ' ' + word\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n",
        "\n",
        "tokenizer = load(open('tools/tokenizer.pkl', 'rb'))\n",
        "max_length = 34\n",
        "model = load_model('model/model_11.h5')\n",
        "photo = extract_features('test.jpg')\n",
        "# Generate the caption\n",
        "description = generate_desc(model, tokenizer, photo, max_length)\n",
        "# Print the caption\n",
        "print(description)"
      ],
      "metadata": {
        "id": "QtXOTFzM9N0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}